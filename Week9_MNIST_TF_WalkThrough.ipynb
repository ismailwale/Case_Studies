{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week9_MNIST_TF_WalkThrough.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toraaglobal/Case_Studies/blob/master/Week9_MNIST_TF_WalkThrough.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpwdyFbG6UPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SINGLE LAYER AND MULTI LAYER NETWORKS FOR MNIST\n",
        "# BASED ON CODE FROM TENSORFLOW TUTORIAL\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-0Sh26C6jRR",
        "colab_type": "code",
        "outputId": "038a292e-0458-4f62-9a2c-e682b2acc871",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# MY TEST TO MAKE SURE TF IS WORKING\n",
        "\n",
        "hello = tf.constant('Hello, TensorFlow!')\n",
        "sess = tf.Session()\n",
        "print(sess.run(hello))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Hello, TensorFlow!'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ut_K3Es6m1n",
        "colab_type": "code",
        "outputId": "7e09d9e8-a17b-4027-e2c8-5ba7fcd16555",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# MY TEST TO MAKE SURE I AM USING GPU\n",
        "\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6atUAhyE6vy3",
        "colab_type": "code",
        "outputId": "2f875142-bff4-42e6-e1a9-c3d049190b10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        }
      },
      "source": [
        "# OBTAIN DATA\n",
        "# DATA WITHIN TF TUTORIAL HAS BEEN PREPROCESSED\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-4-2bad89c735c8>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiZVaH2m60ov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MODEL\n",
        "# CREATE PLACEHOLDER VARIABLES FOR OPERATION MANIPULATION\n",
        "# THE 784 MATCHES THE VECTOR SIZE OF THE MNIST IMAGES - 28*28\n",
        "\n",
        "x = tf.placeholder(tf.float32, [None, 784])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HihwnYn467vI",
        "colab_type": "code",
        "outputId": "4729ce4f-09f7-4906-a09e-2b07d3edbb23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# MODEL\n",
        "# CREATE WEIGHTS & BIASES VARIABLES\n",
        "# IN TF, OUR MODEL PARAMETERS ARE OFTEN MANAGED AS VARIABLES\n",
        "\n",
        "W = tf.Variable(tf.zeros([784, 10]))\n",
        "b = tf.Variable(tf.zeros([10]))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wikJANSm69f4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MODEL\n",
        "# CREATE MODEL - USES SOFTMAX AS THE ACTIVATION FUNCTION\n",
        "# REMEMBER GOAL FOR ACTIVATION FUNCTION IS TO \"SHAPE\" THE \n",
        "# OUTPUT INTO A PROBABILITY DISTRO OVER THE 10 CLASSES\n",
        "\n",
        "y = tf.nn.softmax(tf.matmul(x, W) + b)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT5kUsRb7CXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MODEL\n",
        "# CREATE PREDICTED VARIABLE Y-HAT\n",
        "# AND USE CROSS ENTROPY TO DETERMINE LOSS\n",
        "# CROSS ENTROPY - HOW INEFFICIENT ARE OUR PREDICTIONS?\n",
        "\n",
        "y_ = tf.placeholder(tf.float32, [None, 10])\n",
        "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7jOOxxL7E8g",
        "colab_type": "code",
        "outputId": "1915e8b2-4c36-4f39-8ad8-2a4b8cf449d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# MODEL\n",
        "# TRAIN USING GRADIENT DESCENT\n",
        "# LEARNING RATE AT MIDPOINT - .5 - MAKE SMALL ADJUSTMENTS TO MINIMIZE COST\n",
        "\n",
        "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtCNIMKN7G_I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MODEL - RUN\n",
        "\n",
        "sess = tf.InteractiveSession()\n",
        "tf.global_variables_initializer().run()\n",
        "for _ in range(10000):\n",
        "  batch_xs, batch_ys = mnist.train.next_batch(100)\n",
        "  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IY6FrouH7KTi",
        "colab_type": "code",
        "outputId": "f26b1377-5a59-478c-dd12-695a7b70ecf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# EVALUATE MODEL\n",
        "\n",
        "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9232\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIog9tH9Pagq",
        "colab_type": "text"
      },
      "source": [
        "## Block Two for MNIST on TensorFlow\n",
        "\n",
        "The following code offers an alternative approach to the MNIST classification problem.\n",
        "Using two convolution layers, we can significantly improve upon the original model and explore some of the options for a deep neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQbPWLsBPh6K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# WEIGHT INITIALIZATION\n",
        "\n",
        "def weight_variable(shape):\n",
        "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
        "  return tf.Variable(initial)\n",
        "\n",
        "def bias_variable(shape):\n",
        "  initial = tf.constant(0.1, shape=shape)\n",
        "  return tf.Variable(initial)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7I2ESZ2P1QS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CREATE CONVOLUTION AND POOLING LAYERS\n",
        "\n",
        "def conv2d(x, W):\n",
        "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
        "\n",
        "def max_pool_2x2(x):\n",
        "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
        "                        strides=[1, 2, 2, 1], padding='SAME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nR-H_aaP6EL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# FIRST CONVOLUTION LAYER\n",
        "\n",
        "W_conv1 = weight_variable([5, 5, 1, 32])\n",
        "b_conv1 = bias_variable([32])\n",
        "\n",
        "x_image = tf.reshape(x, [-1, 28, 28, 1]) # BASE IMAGE SIZE OF 28 * 28\n",
        "\n",
        "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
        "h_pool1 = max_pool_2x2(h_conv1)  # RESULTING IMAGE SIZE IS 14 * 14\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgDWQIIWP7Wp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SECOND CONOLUTION LAYER \n",
        "# MORE THAN ONE LAYER?  DEEP LEARNING\n",
        "\n",
        "W_conv2 = weight_variable([5, 5, 32, 64])\n",
        "b_conv2 = bias_variable([64])\n",
        "\n",
        "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
        "h_pool2 = max_pool_2x2(h_conv2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REp4WaT3P_EZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# FULLY CONNECTED LAYER - BEFORE OUTPUT\n",
        "\n",
        "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
        "b_fc1 = bias_variable([1024])\n",
        "\n",
        "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
        "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)  # ADD THE RECTIFIED LINEAR UNIT\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3L7cCEhQBw8",
        "colab_type": "code",
        "outputId": "9c1d3e61-5b30-45c5-eba1-93c9d0896bfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# DROP LAYER - REDUCE OVERFITTING\n",
        "\n",
        "keep_prob = tf.placeholder(tf.float32)\n",
        "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-17-dc93c9c3e1e0>:3: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsNZP5KQQExy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LAST LAYER - OUTPUT\n",
        "\n",
        "W_fc2 = weight_variable([1024, 10])\n",
        "b_fc2 = bias_variable([10])\n",
        "\n",
        "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-WIa7cAQJVE",
        "colab_type": "code",
        "outputId": "9ac6d6a3-1c2b-4d09-f8f0-2b74353f8032",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1955
        }
      },
      "source": [
        "# RUN THE MODEL\n",
        "\n",
        "cross_entropy = tf.reduce_mean(\n",
        "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
        "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
        "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  for i in range(10000):\n",
        "    batch = mnist.train.next_batch(50)\n",
        "    if i % 100 == 0:\n",
        "      train_accuracy = accuracy.eval(feed_dict={\n",
        "          x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
        "      print('step %d, training accuracy %g' % (i, train_accuracy))\n",
        "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
        "\n",
        "  print('test accuracy %g' % accuracy.eval(feed_dict={\n",
        "      x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-20-7e5168658ee2>:3: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "step 0, training accuracy 0.14\n",
            "step 100, training accuracy 0.82\n",
            "step 200, training accuracy 0.92\n",
            "step 300, training accuracy 1\n",
            "step 400, training accuracy 0.96\n",
            "step 500, training accuracy 0.92\n",
            "step 600, training accuracy 0.96\n",
            "step 700, training accuracy 0.98\n",
            "step 800, training accuracy 0.96\n",
            "step 900, training accuracy 0.92\n",
            "step 1000, training accuracy 0.98\n",
            "step 1100, training accuracy 0.96\n",
            "step 1200, training accuracy 0.96\n",
            "step 1300, training accuracy 0.98\n",
            "step 1400, training accuracy 0.94\n",
            "step 1500, training accuracy 0.98\n",
            "step 1600, training accuracy 1\n",
            "step 1700, training accuracy 1\n",
            "step 1800, training accuracy 1\n",
            "step 1900, training accuracy 0.94\n",
            "step 2000, training accuracy 0.98\n",
            "step 2100, training accuracy 0.96\n",
            "step 2200, training accuracy 0.96\n",
            "step 2300, training accuracy 1\n",
            "step 2400, training accuracy 1\n",
            "step 2500, training accuracy 0.96\n",
            "step 2600, training accuracy 0.94\n",
            "step 2700, training accuracy 0.98\n",
            "step 2800, training accuracy 0.96\n",
            "step 2900, training accuracy 1\n",
            "step 3000, training accuracy 1\n",
            "step 3100, training accuracy 1\n",
            "step 3200, training accuracy 0.98\n",
            "step 3300, training accuracy 1\n",
            "step 3400, training accuracy 0.98\n",
            "step 3500, training accuracy 0.98\n",
            "step 3600, training accuracy 0.98\n",
            "step 3700, training accuracy 1\n",
            "step 3800, training accuracy 0.94\n",
            "step 3900, training accuracy 1\n",
            "step 4000, training accuracy 1\n",
            "step 4100, training accuracy 1\n",
            "step 4200, training accuracy 1\n",
            "step 4300, training accuracy 1\n",
            "step 4400, training accuracy 1\n",
            "step 4500, training accuracy 1\n",
            "step 4600, training accuracy 1\n",
            "step 4700, training accuracy 1\n",
            "step 4800, training accuracy 0.98\n",
            "step 4900, training accuracy 0.98\n",
            "step 5000, training accuracy 0.96\n",
            "step 5100, training accuracy 0.96\n",
            "step 5200, training accuracy 1\n",
            "step 5300, training accuracy 1\n",
            "step 5400, training accuracy 1\n",
            "step 5500, training accuracy 0.98\n",
            "step 5600, training accuracy 0.98\n",
            "step 5700, training accuracy 1\n",
            "step 5800, training accuracy 1\n",
            "step 5900, training accuracy 1\n",
            "step 6000, training accuracy 0.98\n",
            "step 6100, training accuracy 0.98\n",
            "step 6200, training accuracy 1\n",
            "step 6300, training accuracy 1\n",
            "step 6400, training accuracy 0.98\n",
            "step 6500, training accuracy 1\n",
            "step 6600, training accuracy 1\n",
            "step 6700, training accuracy 1\n",
            "step 6800, training accuracy 0.98\n",
            "step 6900, training accuracy 1\n",
            "step 7000, training accuracy 1\n",
            "step 7100, training accuracy 0.98\n",
            "step 7200, training accuracy 1\n",
            "step 7300, training accuracy 1\n",
            "step 7400, training accuracy 0.98\n",
            "step 7500, training accuracy 1\n",
            "step 7600, training accuracy 1\n",
            "step 7700, training accuracy 1\n",
            "step 7800, training accuracy 1\n",
            "step 7900, training accuracy 1\n",
            "step 8000, training accuracy 1\n",
            "step 8100, training accuracy 1\n",
            "step 8200, training accuracy 1\n",
            "step 8300, training accuracy 1\n",
            "step 8400, training accuracy 1\n",
            "step 8500, training accuracy 1\n",
            "step 8600, training accuracy 0.98\n",
            "step 8700, training accuracy 1\n",
            "step 8800, training accuracy 1\n",
            "step 8900, training accuracy 1\n",
            "step 9000, training accuracy 1\n",
            "step 9100, training accuracy 1\n",
            "step 9200, training accuracy 1\n",
            "step 9300, training accuracy 1\n",
            "step 9400, training accuracy 0.98\n",
            "step 9500, training accuracy 1\n",
            "step 9600, training accuracy 1\n",
            "step 9700, training accuracy 1\n",
            "step 9800, training accuracy 1\n",
            "step 9900, training accuracy 1\n",
            "test accuracy 0.989\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqcgYvWSdNtk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2891bf4f-fe3b-4b27-a827-dedf0f8dfc94"
      },
      "source": [
        "# BASIC WALK THROUGH FOR MNIST NN\n",
        "# BASED ON KERAS TUTORIALS (2019)\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.utils import np_utils\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0k1UBmRAdlVD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4f9abcce-86a8-4bd9-b612-3941f9aadf63"
      },
      "source": [
        "# OBTAIN\n",
        "\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "# SCRUB\n",
        "# FLATTEN 28 x 28 IMAGE TO 784 VECTOR\n",
        "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
        "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')\n",
        "\n",
        "\n",
        "\n",
        "# SCRUB\n",
        "# NORMALIZE INPUTS FROM RGB COLOR TO 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "\n",
        "\n",
        "# SCRUB\n",
        "# THE OLD ONE HOT ENCODE - CONVERT \"CATEGORICAL\" CLASSIFICATION TO ENCODE\n",
        "# A \"BINARIZATION\" OF THE CATEGORIES\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVQk-aNXX6ZK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 10719
        },
        "outputId": "3e96fc16-709c-4fd7-c1b1-968839199424"
      },
      "source": [
        "# MODEL\n",
        "# BUILD THE BASELINE\n",
        "\n",
        "def baseline_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
        "    # Compile model\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "# MODEL\n",
        "# RUN THE MODEL\n",
        "\n",
        "model = baseline_model()\n",
        "\n",
        "# FIT THE MODEL\n",
        "\n",
        "history  = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=300, batch_size=1000, verbose=2)\n",
        "\n",
        "# EVALUATE THE MODEL\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/300\n",
            " - 1s - loss: 0.5392 - acc: 0.8503 - val_loss: 0.2424 - val_acc: 0.9313\n",
            "Epoch 2/300\n",
            " - 0s - loss: 0.2064 - acc: 0.9423 - val_loss: 0.1715 - val_acc: 0.9514\n",
            "Epoch 3/300\n",
            " - 0s - loss: 0.1497 - acc: 0.9582 - val_loss: 0.1367 - val_acc: 0.9602\n",
            "Epoch 4/300\n",
            " - 0s - loss: 0.1152 - acc: 0.9680 - val_loss: 0.1135 - val_acc: 0.9660\n",
            "Epoch 5/300\n",
            " - 0s - loss: 0.0933 - acc: 0.9741 - val_loss: 0.1023 - val_acc: 0.9687\n",
            "Epoch 6/300\n",
            " - 0s - loss: 0.0784 - acc: 0.9783 - val_loss: 0.0888 - val_acc: 0.9725\n",
            "Epoch 7/300\n",
            " - 0s - loss: 0.0638 - acc: 0.9824 - val_loss: 0.0827 - val_acc: 0.9750\n",
            "Epoch 8/300\n",
            " - 0s - loss: 0.0546 - acc: 0.9852 - val_loss: 0.0754 - val_acc: 0.9767\n",
            "Epoch 9/300\n",
            " - 0s - loss: 0.0462 - acc: 0.9880 - val_loss: 0.0730 - val_acc: 0.9770\n",
            "Epoch 10/300\n",
            " - 0s - loss: 0.0390 - acc: 0.9904 - val_loss: 0.0710 - val_acc: 0.9783\n",
            "Epoch 11/300\n",
            " - 0s - loss: 0.0340 - acc: 0.9919 - val_loss: 0.0661 - val_acc: 0.9791\n",
            "Epoch 12/300\n",
            " - 0s - loss: 0.0292 - acc: 0.9934 - val_loss: 0.0671 - val_acc: 0.9797\n",
            "Epoch 13/300\n",
            " - 0s - loss: 0.0256 - acc: 0.9948 - val_loss: 0.0643 - val_acc: 0.9786\n",
            "Epoch 14/300\n",
            " - 0s - loss: 0.0223 - acc: 0.9959 - val_loss: 0.0620 - val_acc: 0.9800\n",
            "Epoch 15/300\n",
            " - 0s - loss: 0.0194 - acc: 0.9965 - val_loss: 0.0618 - val_acc: 0.9810\n",
            "Epoch 16/300\n",
            " - 0s - loss: 0.0169 - acc: 0.9975 - val_loss: 0.0620 - val_acc: 0.9805\n",
            "Epoch 17/300\n",
            " - 0s - loss: 0.0147 - acc: 0.9978 - val_loss: 0.0597 - val_acc: 0.9810\n",
            "Epoch 18/300\n",
            " - 0s - loss: 0.0128 - acc: 0.9984 - val_loss: 0.0593 - val_acc: 0.9817\n",
            "Epoch 19/300\n",
            " - 0s - loss: 0.0112 - acc: 0.9987 - val_loss: 0.0614 - val_acc: 0.9818\n",
            "Epoch 20/300\n",
            " - 0s - loss: 0.0102 - acc: 0.9989 - val_loss: 0.0589 - val_acc: 0.9814\n",
            "Epoch 21/300\n",
            " - 0s - loss: 0.0086 - acc: 0.9992 - val_loss: 0.0594 - val_acc: 0.9816\n",
            "Epoch 22/300\n",
            " - 0s - loss: 0.0079 - acc: 0.9993 - val_loss: 0.0598 - val_acc: 0.9805\n",
            "Epoch 23/300\n",
            " - 0s - loss: 0.0067 - acc: 0.9997 - val_loss: 0.0581 - val_acc: 0.9814\n",
            "Epoch 24/300\n",
            " - 0s - loss: 0.0060 - acc: 0.9997 - val_loss: 0.0593 - val_acc: 0.9807\n",
            "Epoch 25/300\n",
            " - 0s - loss: 0.0053 - acc: 0.9998 - val_loss: 0.0592 - val_acc: 0.9816\n",
            "Epoch 26/300\n",
            " - 0s - loss: 0.0047 - acc: 0.9998 - val_loss: 0.0601 - val_acc: 0.9821\n",
            "Epoch 27/300\n",
            " - 0s - loss: 0.0042 - acc: 0.9999 - val_loss: 0.0597 - val_acc: 0.9815\n",
            "Epoch 28/300\n",
            " - 0s - loss: 0.0039 - acc: 0.9999 - val_loss: 0.0599 - val_acc: 0.9815\n",
            "Epoch 29/300\n",
            " - 0s - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0604 - val_acc: 0.9814\n",
            "Epoch 30/300\n",
            " - 0s - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0607 - val_acc: 0.9812\n",
            "Epoch 31/300\n",
            " - 0s - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0609 - val_acc: 0.9818\n",
            "Epoch 32/300\n",
            " - 0s - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0606 - val_acc: 0.9811\n",
            "Epoch 33/300\n",
            " - 0s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0614 - val_acc: 0.9812\n",
            "Epoch 34/300\n",
            " - 0s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0610 - val_acc: 0.9820\n",
            "Epoch 35/300\n",
            " - 0s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0611 - val_acc: 0.9821\n",
            "Epoch 36/300\n",
            " - 0s - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0616 - val_acc: 0.9815\n",
            "Epoch 37/300\n",
            " - 0s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0617 - val_acc: 0.9827\n",
            "Epoch 38/300\n",
            " - 0s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0624 - val_acc: 0.9810\n",
            "Epoch 39/300\n",
            " - 0s - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0629 - val_acc: 0.9821\n",
            "Epoch 40/300\n",
            " - 0s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0631 - val_acc: 0.9817\n",
            "Epoch 41/300\n",
            " - 0s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0636 - val_acc: 0.9814\n",
            "Epoch 42/300\n",
            " - 0s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0625 - val_acc: 0.9819\n",
            "Epoch 43/300\n",
            " - 0s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0634 - val_acc: 0.9822\n",
            "Epoch 44/300\n",
            " - 0s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0639 - val_acc: 0.9817\n",
            "Epoch 45/300\n",
            " - 0s - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0641 - val_acc: 0.9821\n",
            "Epoch 46/300\n",
            " - 0s - loss: 9.4225e-04 - acc: 1.0000 - val_loss: 0.0638 - val_acc: 0.9820\n",
            "Epoch 47/300\n",
            " - 0s - loss: 8.9114e-04 - acc: 1.0000 - val_loss: 0.0646 - val_acc: 0.9817\n",
            "Epoch 48/300\n",
            " - 0s - loss: 8.4755e-04 - acc: 1.0000 - val_loss: 0.0645 - val_acc: 0.9821\n",
            "Epoch 49/300\n",
            " - 0s - loss: 7.9386e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9820\n",
            "Epoch 50/300\n",
            " - 0s - loss: 7.6050e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9818\n",
            "Epoch 51/300\n",
            " - 0s - loss: 7.0673e-04 - acc: 1.0000 - val_loss: 0.0656 - val_acc: 0.9815\n",
            "Epoch 52/300\n",
            " - 0s - loss: 6.7289e-04 - acc: 1.0000 - val_loss: 0.0657 - val_acc: 0.9817\n",
            "Epoch 53/300\n",
            " - 0s - loss: 6.4213e-04 - acc: 1.0000 - val_loss: 0.0664 - val_acc: 0.9820\n",
            "Epoch 54/300\n",
            " - 0s - loss: 6.1616e-04 - acc: 1.0000 - val_loss: 0.0663 - val_acc: 0.9818\n",
            "Epoch 55/300\n",
            " - 0s - loss: 5.7057e-04 - acc: 1.0000 - val_loss: 0.0667 - val_acc: 0.9825\n",
            "Epoch 56/300\n",
            " - 0s - loss: 5.4230e-04 - acc: 1.0000 - val_loss: 0.0667 - val_acc: 0.9818\n",
            "Epoch 57/300\n",
            " - 0s - loss: 5.1473e-04 - acc: 1.0000 - val_loss: 0.0670 - val_acc: 0.9818\n",
            "Epoch 58/300\n",
            " - 0s - loss: 4.8722e-04 - acc: 1.0000 - val_loss: 0.0673 - val_acc: 0.9822\n",
            "Epoch 59/300\n",
            " - 0s - loss: 4.6334e-04 - acc: 1.0000 - val_loss: 0.0676 - val_acc: 0.9822\n",
            "Epoch 60/300\n",
            " - 0s - loss: 4.4604e-04 - acc: 1.0000 - val_loss: 0.0680 - val_acc: 0.9821\n",
            "Epoch 61/300\n",
            " - 0s - loss: 4.2167e-04 - acc: 1.0000 - val_loss: 0.0676 - val_acc: 0.9822\n",
            "Epoch 62/300\n",
            " - 0s - loss: 3.9944e-04 - acc: 1.0000 - val_loss: 0.0685 - val_acc: 0.9818\n",
            "Epoch 63/300\n",
            " - 0s - loss: 3.8246e-04 - acc: 1.0000 - val_loss: 0.0684 - val_acc: 0.9818\n",
            "Epoch 64/300\n",
            " - 0s - loss: 3.6830e-04 - acc: 1.0000 - val_loss: 0.0686 - val_acc: 0.9820\n",
            "Epoch 65/300\n",
            " - 0s - loss: 3.4527e-04 - acc: 1.0000 - val_loss: 0.0689 - val_acc: 0.9820\n",
            "Epoch 66/300\n",
            " - 0s - loss: 3.3338e-04 - acc: 1.0000 - val_loss: 0.0689 - val_acc: 0.9822\n",
            "Epoch 67/300\n",
            " - 0s - loss: 3.1640e-04 - acc: 1.0000 - val_loss: 0.0695 - val_acc: 0.9822\n",
            "Epoch 68/300\n",
            " - 0s - loss: 3.0173e-04 - acc: 1.0000 - val_loss: 0.0695 - val_acc: 0.9819\n",
            "Epoch 69/300\n",
            " - 0s - loss: 2.8995e-04 - acc: 1.0000 - val_loss: 0.0699 - val_acc: 0.9818\n",
            "Epoch 70/300\n",
            " - 0s - loss: 2.7761e-04 - acc: 1.0000 - val_loss: 0.0701 - val_acc: 0.9821\n",
            "Epoch 71/300\n",
            " - 0s - loss: 2.6588e-04 - acc: 1.0000 - val_loss: 0.0703 - val_acc: 0.9819\n",
            "Epoch 72/300\n",
            " - 0s - loss: 2.5507e-04 - acc: 1.0000 - val_loss: 0.0699 - val_acc: 0.9819\n",
            "Epoch 73/300\n",
            " - 0s - loss: 2.4467e-04 - acc: 1.0000 - val_loss: 0.0705 - val_acc: 0.9824\n",
            "Epoch 74/300\n",
            " - 0s - loss: 2.3413e-04 - acc: 1.0000 - val_loss: 0.0710 - val_acc: 0.9821\n",
            "Epoch 75/300\n",
            " - 0s - loss: 2.2285e-04 - acc: 1.0000 - val_loss: 0.0712 - val_acc: 0.9820\n",
            "Epoch 76/300\n",
            " - 0s - loss: 2.1214e-04 - acc: 1.0000 - val_loss: 0.0714 - val_acc: 0.9822\n",
            "Epoch 77/300\n",
            " - 0s - loss: 2.0276e-04 - acc: 1.0000 - val_loss: 0.0713 - val_acc: 0.9821\n",
            "Epoch 78/300\n",
            " - 0s - loss: 1.9634e-04 - acc: 1.0000 - val_loss: 0.0720 - val_acc: 0.9822\n",
            "Epoch 79/300\n",
            " - 0s - loss: 1.8948e-04 - acc: 1.0000 - val_loss: 0.0718 - val_acc: 0.9819\n",
            "Epoch 80/300\n",
            " - 0s - loss: 1.7929e-04 - acc: 1.0000 - val_loss: 0.0728 - val_acc: 0.9820\n",
            "Epoch 81/300\n",
            " - 0s - loss: 1.7166e-04 - acc: 1.0000 - val_loss: 0.0724 - val_acc: 0.9822\n",
            "Epoch 82/300\n",
            " - 0s - loss: 1.6490e-04 - acc: 1.0000 - val_loss: 0.0725 - val_acc: 0.9822\n",
            "Epoch 83/300\n",
            " - 0s - loss: 1.5859e-04 - acc: 1.0000 - val_loss: 0.0724 - val_acc: 0.9821\n",
            "Epoch 84/300\n",
            " - 0s - loss: 1.5218e-04 - acc: 1.0000 - val_loss: 0.0730 - val_acc: 0.9823\n",
            "Epoch 85/300\n",
            " - 0s - loss: 1.4668e-04 - acc: 1.0000 - val_loss: 0.0733 - val_acc: 0.9818\n",
            "Epoch 86/300\n",
            " - 0s - loss: 1.4107e-04 - acc: 1.0000 - val_loss: 0.0738 - val_acc: 0.9819\n",
            "Epoch 87/300\n",
            " - 0s - loss: 1.3443e-04 - acc: 1.0000 - val_loss: 0.0737 - val_acc: 0.9823\n",
            "Epoch 88/300\n",
            " - 0s - loss: 1.2929e-04 - acc: 1.0000 - val_loss: 0.0739 - val_acc: 0.9821\n",
            "Epoch 89/300\n",
            " - 0s - loss: 1.2518e-04 - acc: 1.0000 - val_loss: 0.0740 - val_acc: 0.9819\n",
            "Epoch 90/300\n",
            " - 0s - loss: 1.2034e-04 - acc: 1.0000 - val_loss: 0.0742 - val_acc: 0.9820\n",
            "Epoch 91/300\n",
            " - 0s - loss: 1.1544e-04 - acc: 1.0000 - val_loss: 0.0745 - val_acc: 0.9819\n",
            "Epoch 92/300\n",
            " - 0s - loss: 1.0992e-04 - acc: 1.0000 - val_loss: 0.0747 - val_acc: 0.9823\n",
            "Epoch 93/300\n",
            " - 0s - loss: 1.0558e-04 - acc: 1.0000 - val_loss: 0.0756 - val_acc: 0.9819\n",
            "Epoch 94/300\n",
            " - 0s - loss: 1.0269e-04 - acc: 1.0000 - val_loss: 0.0754 - val_acc: 0.9823\n",
            "Epoch 95/300\n",
            " - 0s - loss: 9.8068e-05 - acc: 1.0000 - val_loss: 0.0755 - val_acc: 0.9821\n",
            "Epoch 96/300\n",
            " - 0s - loss: 9.4737e-05 - acc: 1.0000 - val_loss: 0.0755 - val_acc: 0.9819\n",
            "Epoch 97/300\n",
            " - 0s - loss: 9.1180e-05 - acc: 1.0000 - val_loss: 0.0761 - val_acc: 0.9821\n",
            "Epoch 98/300\n",
            " - 0s - loss: 8.7855e-05 - acc: 1.0000 - val_loss: 0.0760 - val_acc: 0.9822\n",
            "Epoch 99/300\n",
            " - 0s - loss: 8.4186e-05 - acc: 1.0000 - val_loss: 0.0767 - val_acc: 0.9820\n",
            "Epoch 100/300\n",
            " - 0s - loss: 8.0863e-05 - acc: 1.0000 - val_loss: 0.0768 - val_acc: 0.9817\n",
            "Epoch 101/300\n",
            " - 0s - loss: 7.8647e-05 - acc: 1.0000 - val_loss: 0.0767 - val_acc: 0.9823\n",
            "Epoch 102/300\n",
            " - 0s - loss: 7.5589e-05 - acc: 1.0000 - val_loss: 0.0772 - val_acc: 0.9817\n",
            "Epoch 103/300\n",
            " - 0s - loss: 7.2300e-05 - acc: 1.0000 - val_loss: 0.0766 - val_acc: 0.9819\n",
            "Epoch 104/300\n",
            " - 0s - loss: 6.9458e-05 - acc: 1.0000 - val_loss: 0.0771 - val_acc: 0.9820\n",
            "Epoch 105/300\n",
            " - 0s - loss: 6.7167e-05 - acc: 1.0000 - val_loss: 0.0778 - val_acc: 0.9822\n",
            "Epoch 106/300\n",
            " - 0s - loss: 6.4964e-05 - acc: 1.0000 - val_loss: 0.0784 - val_acc: 0.9820\n",
            "Epoch 107/300\n",
            " - 0s - loss: 6.2691e-05 - acc: 1.0000 - val_loss: 0.0783 - val_acc: 0.9819\n",
            "Epoch 108/300\n",
            " - 0s - loss: 5.9893e-05 - acc: 1.0000 - val_loss: 0.0782 - val_acc: 0.9819\n",
            "Epoch 109/300\n",
            " - 0s - loss: 5.8101e-05 - acc: 1.0000 - val_loss: 0.0784 - val_acc: 0.9820\n",
            "Epoch 110/300\n",
            " - 0s - loss: 5.5752e-05 - acc: 1.0000 - val_loss: 0.0789 - val_acc: 0.9820\n",
            "Epoch 111/300\n",
            " - 0s - loss: 5.3703e-05 - acc: 1.0000 - val_loss: 0.0788 - val_acc: 0.9820\n",
            "Epoch 112/300\n",
            " - 0s - loss: 5.1883e-05 - acc: 1.0000 - val_loss: 0.0795 - val_acc: 0.9816\n",
            "Epoch 113/300\n",
            " - 0s - loss: 5.0234e-05 - acc: 1.0000 - val_loss: 0.0793 - val_acc: 0.9819\n",
            "Epoch 114/300\n",
            " - 0s - loss: 4.8383e-05 - acc: 1.0000 - val_loss: 0.0794 - val_acc: 0.9823\n",
            "Epoch 115/300\n",
            " - 0s - loss: 4.7149e-05 - acc: 1.0000 - val_loss: 0.0798 - val_acc: 0.9823\n",
            "Epoch 116/300\n",
            " - 0s - loss: 4.4936e-05 - acc: 1.0000 - val_loss: 0.0801 - val_acc: 0.9822\n",
            "Epoch 117/300\n",
            " - 0s - loss: 4.3463e-05 - acc: 1.0000 - val_loss: 0.0798 - val_acc: 0.9820\n",
            "Epoch 118/300\n",
            " - 0s - loss: 4.1669e-05 - acc: 1.0000 - val_loss: 0.0801 - val_acc: 0.9820\n",
            "Epoch 119/300\n",
            " - 0s - loss: 4.0393e-05 - acc: 1.0000 - val_loss: 0.0803 - val_acc: 0.9821\n",
            "Epoch 120/300\n",
            " - 0s - loss: 3.9213e-05 - acc: 1.0000 - val_loss: 0.0806 - val_acc: 0.9823\n",
            "Epoch 121/300\n",
            " - 0s - loss: 3.7505e-05 - acc: 1.0000 - val_loss: 0.0805 - val_acc: 0.9820\n",
            "Epoch 122/300\n",
            " - 0s - loss: 3.5985e-05 - acc: 1.0000 - val_loss: 0.0809 - val_acc: 0.9820\n",
            "Epoch 123/300\n",
            " - 0s - loss: 3.4913e-05 - acc: 1.0000 - val_loss: 0.0812 - val_acc: 0.9820\n",
            "Epoch 124/300\n",
            " - 0s - loss: 3.3504e-05 - acc: 1.0000 - val_loss: 0.0819 - val_acc: 0.9819\n",
            "Epoch 125/300\n",
            " - 0s - loss: 3.2530e-05 - acc: 1.0000 - val_loss: 0.0818 - val_acc: 0.9821\n",
            "Epoch 126/300\n",
            " - 0s - loss: 3.1462e-05 - acc: 1.0000 - val_loss: 0.0820 - val_acc: 0.9819\n",
            "Epoch 127/300\n",
            " - 0s - loss: 3.0262e-05 - acc: 1.0000 - val_loss: 0.0822 - val_acc: 0.9823\n",
            "Epoch 128/300\n",
            " - 0s - loss: 2.9264e-05 - acc: 1.0000 - val_loss: 0.0825 - val_acc: 0.9823\n",
            "Epoch 129/300\n",
            " - 0s - loss: 2.8197e-05 - acc: 1.0000 - val_loss: 0.0826 - val_acc: 0.9820\n",
            "Epoch 130/300\n",
            " - 0s - loss: 2.7355e-05 - acc: 1.0000 - val_loss: 0.0828 - val_acc: 0.9821\n",
            "Epoch 131/300\n",
            " - 0s - loss: 2.6447e-05 - acc: 1.0000 - val_loss: 0.0830 - val_acc: 0.9822\n",
            "Epoch 132/300\n",
            " - 0s - loss: 2.5476e-05 - acc: 1.0000 - val_loss: 0.0833 - val_acc: 0.9821\n",
            "Epoch 133/300\n",
            " - 0s - loss: 2.4623e-05 - acc: 1.0000 - val_loss: 0.0832 - val_acc: 0.9824\n",
            "Epoch 134/300\n",
            " - 0s - loss: 2.3738e-05 - acc: 1.0000 - val_loss: 0.0833 - val_acc: 0.9821\n",
            "Epoch 135/300\n",
            " - 0s - loss: 2.2940e-05 - acc: 1.0000 - val_loss: 0.0836 - val_acc: 0.9821\n",
            "Epoch 136/300\n",
            " - 0s - loss: 2.2111e-05 - acc: 1.0000 - val_loss: 0.0838 - val_acc: 0.9822\n",
            "Epoch 137/300\n",
            " - 0s - loss: 2.1472e-05 - acc: 1.0000 - val_loss: 0.0840 - val_acc: 0.9821\n",
            "Epoch 138/300\n",
            " - 0s - loss: 2.0658e-05 - acc: 1.0000 - val_loss: 0.0843 - val_acc: 0.9820\n",
            "Epoch 139/300\n",
            " - 0s - loss: 2.0162e-05 - acc: 1.0000 - val_loss: 0.0845 - val_acc: 0.9822\n",
            "Epoch 140/300\n",
            " - 0s - loss: 1.9426e-05 - acc: 1.0000 - val_loss: 0.0843 - val_acc: 0.9823\n",
            "Epoch 141/300\n",
            " - 0s - loss: 1.8659e-05 - acc: 1.0000 - val_loss: 0.0848 - val_acc: 0.9822\n",
            "Epoch 142/300\n",
            " - 0s - loss: 1.7943e-05 - acc: 1.0000 - val_loss: 0.0846 - val_acc: 0.9821\n",
            "Epoch 143/300\n",
            " - 0s - loss: 1.7376e-05 - acc: 1.0000 - val_loss: 0.0850 - val_acc: 0.9822\n",
            "Epoch 144/300\n",
            " - 0s - loss: 1.6825e-05 - acc: 1.0000 - val_loss: 0.0854 - val_acc: 0.9820\n",
            "Epoch 145/300\n",
            " - 0s - loss: 1.6279e-05 - acc: 1.0000 - val_loss: 0.0853 - val_acc: 0.9822\n",
            "Epoch 146/300\n",
            " - 0s - loss: 1.5668e-05 - acc: 1.0000 - val_loss: 0.0857 - val_acc: 0.9824\n",
            "Epoch 147/300\n",
            " - 0s - loss: 1.5268e-05 - acc: 1.0000 - val_loss: 0.0862 - val_acc: 0.9821\n",
            "Epoch 148/300\n",
            " - 0s - loss: 1.4597e-05 - acc: 1.0000 - val_loss: 0.0861 - val_acc: 0.9822\n",
            "Epoch 149/300\n",
            " - 0s - loss: 1.4185e-05 - acc: 1.0000 - val_loss: 0.0865 - val_acc: 0.9820\n",
            "Epoch 150/300\n",
            " - 0s - loss: 1.3694e-05 - acc: 1.0000 - val_loss: 0.0863 - val_acc: 0.9822\n",
            "Epoch 151/300\n",
            " - 0s - loss: 1.3218e-05 - acc: 1.0000 - val_loss: 0.0868 - val_acc: 0.9821\n",
            "Epoch 152/300\n",
            " - 0s - loss: 1.2762e-05 - acc: 1.0000 - val_loss: 0.0868 - val_acc: 0.9822\n",
            "Epoch 153/300\n",
            " - 0s - loss: 1.2361e-05 - acc: 1.0000 - val_loss: 0.0872 - val_acc: 0.9822\n",
            "Epoch 154/300\n",
            " - 0s - loss: 1.2022e-05 - acc: 1.0000 - val_loss: 0.0873 - val_acc: 0.9823\n",
            "Epoch 155/300\n",
            " - 0s - loss: 1.1538e-05 - acc: 1.0000 - val_loss: 0.0875 - val_acc: 0.9822\n",
            "Epoch 156/300\n",
            " - 0s - loss: 1.1281e-05 - acc: 1.0000 - val_loss: 0.0878 - val_acc: 0.9822\n",
            "Epoch 157/300\n",
            " - 0s - loss: 1.0924e-05 - acc: 1.0000 - val_loss: 0.0880 - val_acc: 0.9821\n",
            "Epoch 158/300\n",
            " - 0s - loss: 1.0547e-05 - acc: 1.0000 - val_loss: 0.0883 - val_acc: 0.9822\n",
            "Epoch 159/300\n",
            " - 0s - loss: 1.0170e-05 - acc: 1.0000 - val_loss: 0.0880 - val_acc: 0.9821\n",
            "Epoch 160/300\n",
            " - 0s - loss: 9.7683e-06 - acc: 1.0000 - val_loss: 0.0885 - val_acc: 0.9820\n",
            "Epoch 161/300\n",
            " - 0s - loss: 9.5015e-06 - acc: 1.0000 - val_loss: 0.0885 - val_acc: 0.9823\n",
            "Epoch 162/300\n",
            " - 0s - loss: 9.1213e-06 - acc: 1.0000 - val_loss: 0.0887 - val_acc: 0.9821\n",
            "Epoch 163/300\n",
            " - 0s - loss: 8.9036e-06 - acc: 1.0000 - val_loss: 0.0890 - val_acc: 0.9822\n",
            "Epoch 164/300\n",
            " - 0s - loss: 8.6145e-06 - acc: 1.0000 - val_loss: 0.0893 - val_acc: 0.9822\n",
            "Epoch 165/300\n",
            " - 0s - loss: 8.2762e-06 - acc: 1.0000 - val_loss: 0.0895 - val_acc: 0.9824\n",
            "Epoch 166/300\n",
            " - 0s - loss: 8.0380e-06 - acc: 1.0000 - val_loss: 0.0898 - val_acc: 0.9819\n",
            "Epoch 167/300\n",
            " - 0s - loss: 7.7753e-06 - acc: 1.0000 - val_loss: 0.0896 - val_acc: 0.9825\n",
            "Epoch 168/300\n",
            " - 0s - loss: 7.4882e-06 - acc: 1.0000 - val_loss: 0.0897 - val_acc: 0.9822\n",
            "Epoch 169/300\n",
            " - 0s - loss: 7.2918e-06 - acc: 1.0000 - val_loss: 0.0899 - val_acc: 0.9820\n",
            "Epoch 170/300\n",
            " - 0s - loss: 7.0052e-06 - acc: 1.0000 - val_loss: 0.0900 - val_acc: 0.9821\n",
            "Epoch 171/300\n",
            " - 0s - loss: 6.8009e-06 - acc: 1.0000 - val_loss: 0.0900 - val_acc: 0.9821\n",
            "Epoch 172/300\n",
            " - 0s - loss: 6.5778e-06 - acc: 1.0000 - val_loss: 0.0904 - val_acc: 0.9822\n",
            "Epoch 173/300\n",
            " - 0s - loss: 6.3876e-06 - acc: 1.0000 - val_loss: 0.0907 - val_acc: 0.9821\n",
            "Epoch 174/300\n",
            " - 0s - loss: 6.1886e-06 - acc: 1.0000 - val_loss: 0.0909 - val_acc: 0.9820\n",
            "Epoch 175/300\n",
            " - 0s - loss: 5.9642e-06 - acc: 1.0000 - val_loss: 0.0909 - val_acc: 0.9819\n",
            "Epoch 176/300\n",
            " - 0s - loss: 5.7946e-06 - acc: 1.0000 - val_loss: 0.0913 - val_acc: 0.9822\n",
            "Epoch 177/300\n",
            " - 0s - loss: 5.6160e-06 - acc: 1.0000 - val_loss: 0.0912 - val_acc: 0.9823\n",
            "Epoch 178/300\n",
            " - 0s - loss: 5.4136e-06 - acc: 1.0000 - val_loss: 0.0913 - val_acc: 0.9821\n",
            "Epoch 179/300\n",
            " - 0s - loss: 5.2686e-06 - acc: 1.0000 - val_loss: 0.0919 - val_acc: 0.9823\n",
            "Epoch 180/300\n",
            " - 0s - loss: 5.0909e-06 - acc: 1.0000 - val_loss: 0.0915 - val_acc: 0.9820\n",
            "Epoch 181/300\n",
            " - 0s - loss: 4.9500e-06 - acc: 1.0000 - val_loss: 0.0923 - val_acc: 0.9822\n",
            "Epoch 182/300\n",
            " - 0s - loss: 4.7537e-06 - acc: 1.0000 - val_loss: 0.0922 - val_acc: 0.9823\n",
            "Epoch 183/300\n",
            " - 0s - loss: 4.6492e-06 - acc: 1.0000 - val_loss: 0.0927 - val_acc: 0.9823\n",
            "Epoch 184/300\n",
            " - 0s - loss: 4.5181e-06 - acc: 1.0000 - val_loss: 0.0925 - val_acc: 0.9823\n",
            "Epoch 185/300\n",
            " - 0s - loss: 4.3575e-06 - acc: 1.0000 - val_loss: 0.0927 - val_acc: 0.9820\n",
            "Epoch 186/300\n",
            " - 0s - loss: 4.1945e-06 - acc: 1.0000 - val_loss: 0.0933 - val_acc: 0.9822\n",
            "Epoch 187/300\n",
            " - 0s - loss: 4.0622e-06 - acc: 1.0000 - val_loss: 0.0931 - val_acc: 0.9824\n",
            "Epoch 188/300\n",
            " - 0s - loss: 3.9637e-06 - acc: 1.0000 - val_loss: 0.0932 - val_acc: 0.9823\n",
            "Epoch 189/300\n",
            " - 0s - loss: 3.8231e-06 - acc: 1.0000 - val_loss: 0.0936 - val_acc: 0.9822\n",
            "Epoch 190/300\n",
            " - 0s - loss: 3.6979e-06 - acc: 1.0000 - val_loss: 0.0936 - val_acc: 0.9822\n",
            "Epoch 191/300\n",
            " - 0s - loss: 3.5871e-06 - acc: 1.0000 - val_loss: 0.0938 - val_acc: 0.9824\n",
            "Epoch 192/300\n",
            " - 0s - loss: 3.4804e-06 - acc: 1.0000 - val_loss: 0.0941 - val_acc: 0.9824\n",
            "Epoch 193/300\n",
            " - 0s - loss: 3.3703e-06 - acc: 1.0000 - val_loss: 0.0938 - val_acc: 0.9821\n",
            "Epoch 194/300\n",
            " - 0s - loss: 3.2904e-06 - acc: 1.0000 - val_loss: 0.0942 - val_acc: 0.9823\n",
            "Epoch 195/300\n",
            " - 0s - loss: 3.1858e-06 - acc: 1.0000 - val_loss: 0.0945 - val_acc: 0.9820\n",
            "Epoch 196/300\n",
            " - 0s - loss: 3.0740e-06 - acc: 1.0000 - val_loss: 0.0947 - val_acc: 0.9822\n",
            "Epoch 197/300\n",
            " - 0s - loss: 2.9869e-06 - acc: 1.0000 - val_loss: 0.0950 - val_acc: 0.9819\n",
            "Epoch 198/300\n",
            " - 0s - loss: 2.8881e-06 - acc: 1.0000 - val_loss: 0.0950 - val_acc: 0.9821\n",
            "Epoch 199/300\n",
            " - 0s - loss: 2.8005e-06 - acc: 1.0000 - val_loss: 0.0947 - val_acc: 0.9822\n",
            "Epoch 200/300\n",
            " - 0s - loss: 2.7292e-06 - acc: 1.0000 - val_loss: 0.0953 - val_acc: 0.9822\n",
            "Epoch 201/300\n",
            " - 0s - loss: 2.6410e-06 - acc: 1.0000 - val_loss: 0.0952 - val_acc: 0.9822\n",
            "Epoch 202/300\n",
            " - 0s - loss: 2.5735e-06 - acc: 1.0000 - val_loss: 0.0954 - val_acc: 0.9822\n",
            "Epoch 203/300\n",
            " - 0s - loss: 2.4823e-06 - acc: 1.0000 - val_loss: 0.0954 - val_acc: 0.9823\n",
            "Epoch 204/300\n",
            " - 0s - loss: 2.4116e-06 - acc: 1.0000 - val_loss: 0.0960 - val_acc: 0.9825\n",
            "Epoch 205/300\n",
            " - 0s - loss: 2.3381e-06 - acc: 1.0000 - val_loss: 0.0959 - val_acc: 0.9825\n",
            "Epoch 206/300\n",
            " - 0s - loss: 2.2698e-06 - acc: 1.0000 - val_loss: 0.0960 - val_acc: 0.9822\n",
            "Epoch 207/300\n",
            " - 0s - loss: 2.2156e-06 - acc: 1.0000 - val_loss: 0.0967 - val_acc: 0.9823\n",
            "Epoch 208/300\n",
            " - 0s - loss: 2.1415e-06 - acc: 1.0000 - val_loss: 0.0964 - val_acc: 0.9822\n",
            "Epoch 209/300\n",
            " - 0s - loss: 2.0802e-06 - acc: 1.0000 - val_loss: 0.0965 - val_acc: 0.9823\n",
            "Epoch 210/300\n",
            " - 0s - loss: 2.0172e-06 - acc: 1.0000 - val_loss: 0.0966 - val_acc: 0.9821\n",
            "Epoch 211/300\n",
            " - 0s - loss: 1.9668e-06 - acc: 1.0000 - val_loss: 0.0967 - val_acc: 0.9821\n",
            "Epoch 212/300\n",
            " - 0s - loss: 1.9030e-06 - acc: 1.0000 - val_loss: 0.0968 - val_acc: 0.9821\n",
            "Epoch 213/300\n",
            " - 0s - loss: 1.8452e-06 - acc: 1.0000 - val_loss: 0.0974 - val_acc: 0.9821\n",
            "Epoch 214/300\n",
            " - 0s - loss: 1.8002e-06 - acc: 1.0000 - val_loss: 0.0974 - val_acc: 0.9823\n",
            "Epoch 215/300\n",
            " - 0s - loss: 1.7391e-06 - acc: 1.0000 - val_loss: 0.0976 - val_acc: 0.9819\n",
            "Epoch 216/300\n",
            " - 0s - loss: 1.6869e-06 - acc: 1.0000 - val_loss: 0.0978 - val_acc: 0.9822\n",
            "Epoch 217/300\n",
            " - 0s - loss: 1.6500e-06 - acc: 1.0000 - val_loss: 0.0976 - val_acc: 0.9823\n",
            "Epoch 218/300\n",
            " - 0s - loss: 1.6062e-06 - acc: 1.0000 - val_loss: 0.0979 - val_acc: 0.9822\n",
            "Epoch 219/300\n",
            " - 0s - loss: 1.5561e-06 - acc: 1.0000 - val_loss: 0.0982 - val_acc: 0.9822\n",
            "Epoch 220/300\n",
            " - 0s - loss: 1.5106e-06 - acc: 1.0000 - val_loss: 0.0978 - val_acc: 0.9823\n",
            "Epoch 221/300\n",
            " - 0s - loss: 1.4760e-06 - acc: 1.0000 - val_loss: 0.0982 - val_acc: 0.9822\n",
            "Epoch 222/300\n",
            " - 0s - loss: 1.4245e-06 - acc: 1.0000 - val_loss: 0.0990 - val_acc: 0.9822\n",
            "Epoch 223/300\n",
            " - 0s - loss: 1.3900e-06 - acc: 1.0000 - val_loss: 0.0985 - val_acc: 0.9821\n",
            "Epoch 224/300\n",
            " - 0s - loss: 1.3514e-06 - acc: 1.0000 - val_loss: 0.0990 - val_acc: 0.9823\n",
            "Epoch 225/300\n",
            " - 0s - loss: 1.3196e-06 - acc: 1.0000 - val_loss: 0.0994 - val_acc: 0.9823\n",
            "Epoch 226/300\n",
            " - 0s - loss: 1.2823e-06 - acc: 1.0000 - val_loss: 0.0994 - val_acc: 0.9823\n",
            "Epoch 227/300\n",
            " - 0s - loss: 1.2482e-06 - acc: 1.0000 - val_loss: 0.0993 - val_acc: 0.9824\n",
            "Epoch 228/300\n",
            " - 0s - loss: 1.2123e-06 - acc: 1.0000 - val_loss: 0.0995 - val_acc: 0.9823\n",
            "Epoch 229/300\n",
            " - 0s - loss: 1.1860e-06 - acc: 1.0000 - val_loss: 0.0993 - val_acc: 0.9821\n",
            "Epoch 230/300\n",
            " - 0s - loss: 1.1471e-06 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9823\n",
            "Epoch 231/300\n",
            " - 0s - loss: 1.1280e-06 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9825\n",
            "Epoch 232/300\n",
            " - 0s - loss: 1.0956e-06 - acc: 1.0000 - val_loss: 0.1000 - val_acc: 0.9823\n",
            "Epoch 233/300\n",
            " - 0s - loss: 1.0590e-06 - acc: 1.0000 - val_loss: 0.1004 - val_acc: 0.9824\n",
            "Epoch 234/300\n",
            " - 0s - loss: 1.0321e-06 - acc: 1.0000 - val_loss: 0.1001 - val_acc: 0.9823\n",
            "Epoch 235/300\n",
            " - 0s - loss: 1.0039e-06 - acc: 1.0000 - val_loss: 0.1005 - val_acc: 0.9823\n",
            "Epoch 236/300\n",
            " - 0s - loss: 9.8001e-07 - acc: 1.0000 - val_loss: 0.1006 - val_acc: 0.9822\n",
            "Epoch 237/300\n",
            " - 0s - loss: 9.5671e-07 - acc: 1.0000 - val_loss: 0.1006 - val_acc: 0.9825\n",
            "Epoch 238/300\n",
            " - 0s - loss: 9.2984e-07 - acc: 1.0000 - val_loss: 0.1007 - val_acc: 0.9821\n",
            "Epoch 239/300\n",
            " - 0s - loss: 9.0691e-07 - acc: 1.0000 - val_loss: 0.1009 - val_acc: 0.9822\n",
            "Epoch 240/300\n",
            " - 0s - loss: 8.8210e-07 - acc: 1.0000 - val_loss: 0.1013 - val_acc: 0.9823\n",
            "Epoch 241/300\n",
            " - 0s - loss: 8.6348e-07 - acc: 1.0000 - val_loss: 0.1012 - val_acc: 0.9823\n",
            "Epoch 242/300\n",
            " - 0s - loss: 8.4321e-07 - acc: 1.0000 - val_loss: 0.1012 - val_acc: 0.9823\n",
            "Epoch 243/300\n",
            " - 0s - loss: 8.1769e-07 - acc: 1.0000 - val_loss: 0.1014 - val_acc: 0.9821\n",
            "Epoch 244/300\n",
            " - 0s - loss: 8.0016e-07 - acc: 1.0000 - val_loss: 0.1015 - val_acc: 0.9823\n",
            "Epoch 245/300\n",
            " - 0s - loss: 7.7891e-07 - acc: 1.0000 - val_loss: 0.1018 - val_acc: 0.9822\n",
            "Epoch 246/300\n",
            " - 0s - loss: 7.6194e-07 - acc: 1.0000 - val_loss: 0.1019 - val_acc: 0.9824\n",
            "Epoch 247/300\n",
            " - 0s - loss: 7.4631e-07 - acc: 1.0000 - val_loss: 0.1018 - val_acc: 0.9823\n",
            "Epoch 248/300\n",
            " - 0s - loss: 7.2353e-07 - acc: 1.0000 - val_loss: 0.1021 - val_acc: 0.9823\n",
            "Epoch 249/300\n",
            " - 0s - loss: 7.0780e-07 - acc: 1.0000 - val_loss: 0.1021 - val_acc: 0.9823\n",
            "Epoch 250/300\n",
            " - 0s - loss: 6.9082e-07 - acc: 1.0000 - val_loss: 0.1025 - val_acc: 0.9822\n",
            "Epoch 251/300\n",
            " - 0s - loss: 6.7516e-07 - acc: 1.0000 - val_loss: 0.1029 - val_acc: 0.9824\n",
            "Epoch 252/300\n",
            " - 0s - loss: 6.6384e-07 - acc: 1.0000 - val_loss: 0.1029 - val_acc: 0.9825\n",
            "Epoch 253/300\n",
            " - 0s - loss: 6.4474e-07 - acc: 1.0000 - val_loss: 0.1030 - val_acc: 0.9820\n",
            "Epoch 254/300\n",
            " - 0s - loss: 6.3193e-07 - acc: 1.0000 - val_loss: 0.1028 - val_acc: 0.9824\n",
            "Epoch 255/300\n",
            " - 0s - loss: 6.1619e-07 - acc: 1.0000 - val_loss: 0.1029 - val_acc: 0.9823\n",
            "Epoch 256/300\n",
            " - 0s - loss: 6.0219e-07 - acc: 1.0000 - val_loss: 0.1029 - val_acc: 0.9823\n",
            "Epoch 257/300\n",
            " - 0s - loss: 5.8760e-07 - acc: 1.0000 - val_loss: 0.1032 - val_acc: 0.9824\n",
            "Epoch 258/300\n",
            " - 0s - loss: 5.7684e-07 - acc: 1.0000 - val_loss: 0.1031 - val_acc: 0.9824\n",
            "Epoch 259/300\n",
            " - 0s - loss: 5.6596e-07 - acc: 1.0000 - val_loss: 0.1034 - val_acc: 0.9824\n",
            "Epoch 260/300\n",
            " - 0s - loss: 5.4952e-07 - acc: 1.0000 - val_loss: 0.1042 - val_acc: 0.9821\n",
            "Epoch 261/300\n",
            " - 0s - loss: 5.3956e-07 - acc: 1.0000 - val_loss: 0.1038 - val_acc: 0.9824\n",
            "Epoch 262/300\n",
            " - 0s - loss: 5.2741e-07 - acc: 1.0000 - val_loss: 0.1041 - val_acc: 0.9820\n",
            "Epoch 263/300\n",
            " - 0s - loss: 5.1609e-07 - acc: 1.0000 - val_loss: 0.1041 - val_acc: 0.9824\n",
            "Epoch 264/300\n",
            " - 0s - loss: 5.0491e-07 - acc: 1.0000 - val_loss: 0.1043 - val_acc: 0.9823\n",
            "Epoch 265/300\n",
            " - 0s - loss: 4.9515e-07 - acc: 1.0000 - val_loss: 0.1044 - val_acc: 0.9823\n",
            "Epoch 266/300\n",
            " - 0s - loss: 4.8501e-07 - acc: 1.0000 - val_loss: 0.1043 - val_acc: 0.9821\n",
            "Epoch 267/300\n",
            " - 0s - loss: 4.7531e-07 - acc: 1.0000 - val_loss: 0.1045 - val_acc: 0.9824\n",
            "Epoch 268/300\n",
            " - 0s - loss: 4.6514e-07 - acc: 1.0000 - val_loss: 0.1047 - val_acc: 0.9821\n",
            "Epoch 269/300\n",
            " - 0s - loss: 4.5783e-07 - acc: 1.0000 - val_loss: 0.1050 - val_acc: 0.9822\n",
            "Epoch 270/300\n",
            " - 0s - loss: 4.4788e-07 - acc: 1.0000 - val_loss: 0.1049 - val_acc: 0.9821\n",
            "Epoch 271/300\n",
            " - 0s - loss: 4.3895e-07 - acc: 1.0000 - val_loss: 0.1048 - val_acc: 0.9824\n",
            "Epoch 272/300\n",
            " - 0s - loss: 4.2939e-07 - acc: 1.0000 - val_loss: 0.1050 - val_acc: 0.9822\n",
            "Epoch 273/300\n",
            " - 0s - loss: 4.2232e-07 - acc: 1.0000 - val_loss: 0.1053 - val_acc: 0.9823\n",
            "Epoch 274/300\n",
            " - 0s - loss: 4.1318e-07 - acc: 1.0000 - val_loss: 0.1054 - val_acc: 0.9822\n",
            "Epoch 275/300\n",
            " - 0s - loss: 4.0490e-07 - acc: 1.0000 - val_loss: 0.1055 - val_acc: 0.9823\n",
            "Epoch 276/300\n",
            " - 0s - loss: 3.9911e-07 - acc: 1.0000 - val_loss: 0.1058 - val_acc: 0.9821\n",
            "Epoch 277/300\n",
            " - 0s - loss: 3.9199e-07 - acc: 1.0000 - val_loss: 0.1058 - val_acc: 0.9822\n",
            "Epoch 278/300\n",
            " - 0s - loss: 3.8395e-07 - acc: 1.0000 - val_loss: 0.1062 - val_acc: 0.9821\n",
            "Epoch 279/300\n",
            " - 0s - loss: 3.7755e-07 - acc: 1.0000 - val_loss: 0.1063 - val_acc: 0.9822\n",
            "Epoch 280/300\n",
            " - 0s - loss: 3.7111e-07 - acc: 1.0000 - val_loss: 0.1060 - val_acc: 0.9823\n",
            "Epoch 281/300\n",
            " - 0s - loss: 3.6511e-07 - acc: 1.0000 - val_loss: 0.1064 - val_acc: 0.9823\n",
            "Epoch 282/300\n",
            " - 0s - loss: 3.5889e-07 - acc: 1.0000 - val_loss: 0.1066 - val_acc: 0.9820\n",
            "Epoch 283/300\n",
            " - 0s - loss: 3.5198e-07 - acc: 1.0000 - val_loss: 0.1064 - val_acc: 0.9824\n",
            "Epoch 284/300\n",
            " - 0s - loss: 3.4590e-07 - acc: 1.0000 - val_loss: 0.1064 - val_acc: 0.9822\n",
            "Epoch 285/300\n",
            " - 0s - loss: 3.4098e-07 - acc: 1.0000 - val_loss: 0.1068 - val_acc: 0.9822\n",
            "Epoch 286/300\n",
            " - 0s - loss: 3.3661e-07 - acc: 1.0000 - val_loss: 0.1070 - val_acc: 0.9823\n",
            "Epoch 287/300\n",
            " - 0s - loss: 3.2950e-07 - acc: 1.0000 - val_loss: 0.1071 - val_acc: 0.9824\n",
            "Epoch 288/300\n",
            " - 0s - loss: 3.2555e-07 - acc: 1.0000 - val_loss: 0.1071 - val_acc: 0.9822\n",
            "Epoch 289/300\n",
            " - 0s - loss: 3.1879e-07 - acc: 1.0000 - val_loss: 0.1073 - val_acc: 0.9822\n",
            "Epoch 290/300\n",
            " - 0s - loss: 3.1421e-07 - acc: 1.0000 - val_loss: 0.1074 - val_acc: 0.9823\n",
            "Epoch 291/300\n",
            " - 0s - loss: 3.0938e-07 - acc: 1.0000 - val_loss: 0.1075 - val_acc: 0.9822\n",
            "Epoch 292/300\n",
            " - 0s - loss: 3.0503e-07 - acc: 1.0000 - val_loss: 0.1077 - val_acc: 0.9825\n",
            "Epoch 293/300\n",
            " - 0s - loss: 3.0051e-07 - acc: 1.0000 - val_loss: 0.1075 - val_acc: 0.9822\n",
            "Epoch 294/300\n",
            " - 0s - loss: 2.9560e-07 - acc: 1.0000 - val_loss: 0.1078 - val_acc: 0.9823\n",
            "Epoch 295/300\n",
            " - 0s - loss: 2.9135e-07 - acc: 1.0000 - val_loss: 0.1079 - val_acc: 0.9821\n",
            "Epoch 296/300\n",
            " - 0s - loss: 2.8725e-07 - acc: 1.0000 - val_loss: 0.1080 - val_acc: 0.9823\n",
            "Epoch 297/300\n",
            " - 0s - loss: 2.8302e-07 - acc: 1.0000 - val_loss: 0.1082 - val_acc: 0.9823\n",
            "Epoch 298/300\n",
            " - 0s - loss: 2.7923e-07 - acc: 1.0000 - val_loss: 0.1083 - val_acc: 0.9822\n",
            "Epoch 299/300\n",
            " - 0s - loss: 2.7563e-07 - acc: 1.0000 - val_loss: 0.1081 - val_acc: 0.9821\n",
            "Epoch 300/300\n",
            " - 0s - loss: 2.7170e-07 - acc: 1.0000 - val_loss: 0.1083 - val_acc: 0.9823\n",
            "Baseline Error: 1.77%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcY7HQNcdAkz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "outputId": "8416f88b-60b0-48b4-80c5-80c6a7657065"
      },
      "source": [
        "# INTERPRET \n",
        "# BUILD FUNCTION FOR PLOTTING THE RESULTS OF THE MODEL\n",
        "\n",
        "def plot_train_curve(history):\n",
        "    colors = ['#e66101','#fdb863','#b2abd2','#5e3c99']\n",
        "    accuracy = history.history['acc']\n",
        "    val_accuracy = history.history['val_acc']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    epochs = range(len(accuracy))\n",
        "    with plt.style.context(\"ggplot\"):\n",
        "        plt.figure(figsize=(8, 8/1.618))\n",
        "        plt.plot(epochs, accuracy, marker='o', c=colors[3], label='Training accuracy')\n",
        "        plt.plot(epochs, val_accuracy, c=colors[0], label='Validation accuracy')\n",
        "        plt.title('Training and validation accuracy')\n",
        "        plt.legend()\n",
        "        plt.figure(figsize=(8, 8/1.618))\n",
        "        plt.plot(epochs, loss, marker='o', c=colors[3], label='Training loss')\n",
        "        plt.plot(epochs, val_loss, c=colors[0], label='Validation loss')\n",
        "        plt.title('Training and validation loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "    \n",
        "plot_train_curve(history)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAE9CAYAAAAmijrUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhRBCiAAhTVsIIYQIEP8D55eVl8c5wEYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x355.995 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAE9CAYAAAAxqKodAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/D9ArkvMpswrGwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x355.995 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwGLESbPeWje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}